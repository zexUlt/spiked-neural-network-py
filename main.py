# -*- coding: utf-8 -*-
"""Sigmoidal DNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16XvrPIf2qbDt_9okA4Ur4SvC5aXCBpWQ


TODO:
    + Make a data array of Izhikevich neuron output https://www.izhikevich.org/publications/whichmod.htm#izhikevich
"""

import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple

from SpikedNN import ProjectorlessSDNN, SpikedNN
from activation_functions import Sigmoid, Izhikevich
from data_generator import DataGenerator
from data_producer import IzhikevichProducer
from projectors import SaturatedProjector, NullProjector
from gamma_func import MultiplicativeGamma

"""# Initial system"""


def aa(t):
    res = np.array([[np.cos(t), np.sin(t)],
                    [-np.sin(t), np.cos(t)]])
    return np.array(res)


def bb(t):
    return np.array([[np.cos(t), 0],
                     [0, np.sin(t)]])


def uu(t):
    return np.array([[np.exp(np.sin(t)), np.exp(np.sin(t)) * (1 - np.cos(t) + np.sin(t))]]).T


def xx(t):
    return np.array([[np.exp(np.sin(t)) * (1 - np.cos(t) + np.sin(t)), np.exp(np.sin(t))]]).T


def initialize_base_vars(x_shape: int, u_shape: int):
    time_end = 6 * np.pi
    step = 1e-4
    time = np.arange(0, time_end, step)

    producer = IzhikevichProducer((1, x_shape))
    data_gen = DataGenerator(n=len(time), producer=producer)

    x_in = xx(time)
    u_in = uu(time)
    # x_in = data_gen.generate(time)
    # u_in = np.ones(shape=(time.shape[0], u_shape)) * 15.

    return time_end, step, x_in, u_in, time


def draw_smth(time: np.array, x_in: np.array, x_pred: np.array, loss: np.array, w_a: np.array, w_b: np.array):
    # noinspection PyTypeChecker
    fig, ax = plt.subplots(ncols=2, figsize=(15, 3), sharex=True, sharey=False)
    ax[0].plot(time, x_in[:, 0, :], label=f"x0 input")
    ax[0].plot(time, x_pred[:, 0, :], label=f"x0 output")
    ax[0].set_title('x0')
    ax[0].legend()
    # ax[0].set_ylim([-6, 6])

    ax[1].plot(time, x_in[:, 1, :], label=f"x1 input")
    ax[1].plot(time, x_pred[:, 1, :], label=f"x1 output")
    ax[1].set_title('x1')
    ax[1].legend()
    # ax[1].set_ylim([-6, 3.3])
    plt.show()

    # noinspection PyTypeChecker
    fig, ax = plt.subplots(ncols=2, figsize=(15, 2), sharex=True, sharey=False)
    ax[0].plot(time[:-1], loss[:, 0, :], label=f"loss1")
    ax[0].legend()
    ax[1].plot(time[:-1], loss[:, 1, :], label=f"loss2")
    ax[1].legend()
    plt.show()

    fig, ax = plt.subplots(ncols=2, figsize=(15, 2), sharex=True, sharey=False)
    ax[0].plot(time[:-1], np.linalg.norm(w_a, axis=(1, 2))[:-1], label=f"w_1")
    ax[0].legend()
    ax[1].plot(time[:-1], np.linalg.norm(w_b, axis=(1, 2))[:-1], label=f"w_2")
    ax[1].legend()
    plt.show()


def get_variables_shapes(dim1, dim2, state_size, u_size):
    b1 = dim1
    c1 = (state_size, dim1)
    d1 = dim1
    e1 = dim1

    b2 = (dim2, u_size)
    c2 = (state_size, dim2, u_size)
    d2 = (dim2, u_size)
    e2 = (dim2, u_size)

    return b1, c1, d1, e1, b2, c2, d2, e2


def plot_initial_system():
    xlim = 2 * np.pi
    # xlim = time_end

    dx = np.array([aa(t) @ xx(t) + bb(t) @ uu(t) for t in time])

    a = np.array([aa(t) for t in time])
    a_eigs = np.linalg.eig(a)[0]

    b = np.array([bb(t) for t in time])
    b_eigs = np.linalg.eig(b)[0]

    init_fig, init_ax = plt.subplots(ncols=2, figsize=(15, 3), sharex='all', sharey='none')
    init_ax[0].plot(time, x_input[:, 0, :])  # , label=f"lr={res.learning_rate}")
    init_ax[0].set_title('x0')
    # ax[0].legend()
    init_ax[1].plot(time, x_input[:, 1, :])  # , label=f"lr={res.learning_rate}")
    init_ax[1].set_title('x1')
    # ax[1].legend()
    init_ax[0].set_xlim(0, xlim)
    init_ax[1].set_xlim(0, xlim)
    init_fig.text(0.05, 0.5, 'X input', ha='center', va='center', rotation='vertical', fontsize=14)
    plt.show()

    init_fig, init_ax = plt.subplots(ncols=2, figsize=(15, 3), sharex='all', sharey='none')
    init_ax[0].plot(time, u_input[:, 0, :])  # , label=f"lr={res.learning_rate}")
    init_ax[0].set_title('u0')
    # ax[0].legend()
    init_ax[1].plot(time, u_input[:, 1, :])  # , label=f"lr={res.learning_rate}")
    init_ax[1].set_title('u1')
    # ax[1].legend()
    init_ax[0].set_xlim(0, xlim)
    init_ax[1].set_xlim(0, xlim)
    init_fig.text(0.05, 0.5, 'U input', ha='center', va='center', rotation='vertical', fontsize=14)
    plt.show()

    init_fig, init_ax = plt.subplots(ncols=2, figsize=(15, 3), sharex='all', sharey='none')
    init_ax[0].plot(time, dx[:, 0, :])  # , label=f"lr={res.learning_rate}")
    init_ax[0].set_title('dx0')
    # ax[0].legend()
    init_ax[1].plot(time, dx[:, 1, :])  # , label=f"lr={res.learning_rate}")
    init_ax[1].set_title('dx1')
    # ax[1].legend()
    init_ax[0].set_xlim(0, xlim)
    init_ax[1].set_xlim(0, xlim)
    init_fig.text(0.05, 0.5, 'dX input', ha='center', va='center', rotation='vertical', fontsize=14)
    plt.show()

    init_fig, init_ax = plt.subplots(ncols=2, figsize=(15, 3), sharex='all', sharey='none')
    init_ax[0].plot(time, a_eigs[:, 0])
    init_ax[0].set_title('A_eigs0')
    # ax[0].legend()
    init_ax[1].plot(time, a_eigs[:, 1])
    init_ax[1].set_title('A_eigs1')
    # ax[1].legend()
    init_ax[0].set_xlim(0, xlim)
    init_ax[1].set_xlim(0, xlim)
    init_fig.text(0.05, 0.5, 'A eigenvalues', ha='center', va='center', rotation='vertical', fontsize=14)
    plt.show()

    init_fig, init_ax = plt.subplots(ncols=2, figsize=(15, 3), sharex='all', sharey='none')
    init_ax[0].plot(time, b_eigs[:, 0])
    init_ax[0].set_title('B_eigs0')
    # ax[0].legend()
    init_ax[1].plot(time, b_eigs[:, 1])
    init_ax[1].set_title('B_eigs1')
    # ax[1].legend()
    init_ax[0].set_xlim(0, xlim)
    init_ax[1].set_xlim(0, xlim)
    init_fig.text(0.05, 0.5, 'B eigenvalues', ha='center', va='center', rotation='vertical', fontsize=14)
    plt.show()


def init_dnn(params: dict):
    np.random.seed(2)

    # b1 = np.random.random(b1_shape) * 10
    b1 = np.zeros(b1_shape)
    # c1 = np.random.random(c1_shape) * 10
    c1 = np.ones(c1_shape) * -1
    # d1 = np.random.random(d1_shape) * 10
    d1 = np.ones(d1_shape) * 0.5
    e1 = np.zeros(e1_shape)
    # b2 = np.random.random(b2_shape) * 10
    b2 = np.zeros(b2_shape)
    # c2 = np.random.random(c2_shape) * 10
    c2 = np.ones(c2_shape) * -1
    # d2 = np.random.random(d2_shape) * 10
    d2 = np.ones(d2_shape) * 0.5
    e2 = np.zeros(e2_shape)

    sigma = Sigmoid(nn1, 1, b1, c1, d1, e1)
    phi = Sigmoid(nn2, u_size, b2, c2, d2, e2)

    params['sigma_1'] = sigma
    params['sigma_2'] = phi

    gamma_1 = MultiplicativeGamma(param=params['c_1'], is_inner=True, weight_matrix=params['p_internal'])
    gamma_2 = MultiplicativeGamma(param=params['c_2'], is_inner=False, weight_matrix=params['p_external'])

    params['gamma_1'] = gamma_1
    params['gamma_2'] = gamma_2

    s_dnn = ProjectorlessSDNN(**params)

    return s_dnn


def process(model):
    model.fit(x=x_input, u=u_input, step=step)

    loss_norm = np.sum(np.linalg.norm(model.history_loss, axis=1))
    loss_delta = np.sum(list(map(lambda el: np.transpose(el) @ el, model.history_loss)))

    print(f"Loss Norm:\t{loss_norm}")
    print(f"Loss Delta:\t{loss_delta}")

    return model


def run_test_1(model):
    model = process(model)

    x = np.array(model.history_x)
    loss = np.array(model.history_loss)

    draw_smth(time=time, x_in=x_input, x_pred=x, loss=loss, w_a=np.asarray(model.history_Wa),
              w_b=np.asarray(model.history_Wb))

    # noinspection PyTypeChecker
    fig, ax = plt.subplots(nrows=max(model.nn1, model.nn2), ncols=2, figsize=(15, 5), sharex=True, sharey=False)
    s_dnn_sigma = np.array(model.history_sigma)
    s_dnn_phi_u = np.array(model.history_phi_U)

    # sigma
    for i in range(model.nn1):
        ax[i, 0].plot(time[:-1], s_dnn_sigma[:, i])
        ax[i, 0].set_title(f'$\\sigma_{{{i}}} (x) $')
        # ax[i, 0].set_xlim(0,xlim)

    # phi
    for i in range(model.nn2):
        ax[i, 1].plot(time[:-1], s_dnn_phi_u[:, i])
        ax[i, 1].set_title(f'$\\varphi_{{{i}}} (x) u$')
        # ax[i, 1].set_xlim(0,xlim)

    plt.show()


def run_test_2(model):
    model = process(model)

    x = np.array(model.history_x)
    loss = np.array(model.history_loss)
    draw_smth(time, x_input, x, loss)


def tune(params: dict) -> Tuple:
    c_1_start, c_1_end, c_1_step = params['c_1']
    c_2_start, c_2_end, c_2_step = params['c_2']
    el_coef_start, el_coef_end, el_coef_step = params['ellipse_coef']
    best_score = float('inf')
    best_params = ...

    # tune_params = {}

    for c_1 in np.arange(c_1_start, c_1_end, c_1_step, dtype=float):
        for c_2 in np.arange(c_2_start, c_2_end, c_2_step, dtype=float):
            for ellipse_coef in np.arange(el_coef_start, el_coef_end, el_coef_step, dtype=float):
                print(f'Tuned params: с_1={c_1}, с_2={c_2}, ellipse_scale={ellipse_coef}')
                dnn_params = {
                    'state_size': state_size,
                    'u_size': u_size,
                    'k1': 10,
                    'k2': 10,
                    'nn1': nn1,
                    'nn2': nn2,
                    'wa_init': np.random.rand(state_size, nn1) * 1e-1,
                    'wb_init': np.random.rand(u_size, nn2) * 1e-1,
                    'a_init': np.identity(2) * -0.99,
                    'p_init': np.array([[10.0, 0.0], [0.0, 40.0]]) * 10,
                    'p_internal': np.diag(np.ones(state_size * nn1, dtype=float) * ellipse_coef),
                    'p_external': np.diag(np.ones(u_size * nn2, dtype=float) * ellipse_coef / 2),
                    'c_1': c_1,
                    'c_2': c_2,
                    'stop_time': time_end,
                    'use_x_hat': False
                }
                s_dnn = init_dnn(dnn_params).fit(x=x_input, u=u_input, step=step)

                loss_norm = np.sum(np.linalg.norm(s_dnn.history_loss, axis=1))
                loss_delta = np.sum(list(map(lambda el: np.transpose(el) @ el, s_dnn.history_loss)))

                print(f"Loss Norm:\t{loss_norm}")
                print(f"Loss Delta:\t{loss_delta}\n")

                if loss_norm < best_score:
                    best_params = (c_1, c_2, ellipse_coef)
                    best_score = loss_norm

    print(f'Best score: {best_score}', f'Best params: {best_params}', end='\n')
    return best_params


time_end = ...
x_input = ...
u_input = ...
step = ...
time = ...

if __name__ == '__main__':
    nn1 = 2
    nn2 = 2
    state_size = 2
    u_size = 2

    b1_shape, c1_shape, d1_shape, e1_shape, \
        b2_shape, c2_shape, d2_shape, e2_shape = get_variables_shapes(dim1=nn1, dim2=nn2,
                                                                      state_size=state_size,
                                                                      u_size=u_size)

    time_end, step, x_input, u_input, time = initialize_base_vars(x_shape=state_size, u_shape=u_size)

    # best_params = tune({'c_1': (0.1, 2., 0.1), 'c_2': (0.1, 2., 0.1), 'ellipse_coef': (0.1, 1, 0.1)})
    dnn_params = {
        'state_size': state_size,
        'u_size': u_size,
        'k1': 10,
        'k2': 10,
        'nn1': nn1,
        'nn2': nn2,
        'wa_init': np.random.rand(state_size, nn1) * 1e-1,
        'wb_init': np.random.rand(u_size, nn2) * 1e-1,
        'a_init': np.identity(2) * -0.99,
        'p_init': np.array([[10.0, 0.0], [0.0, 40.0]]) * 10,
        'p_internal': np.eye(state_size * nn1, dtype=float),
        'p_external': np.eye(u_size * nn2, dtype=float) * 0.25,
        'c_1': 0.001,
        'c_2': 0.001,
        'stop_time': time_end,
        'use_x_hat': False
    }

    model = init_dnn(dnn_params)

    run_test_1(model)
    # run_test_2(model)
